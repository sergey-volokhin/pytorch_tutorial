{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "      <th>rtAllCriticsRating</th>\n",
       "      <th>rtAllCriticsNumFresh</th>\n",
       "      <th>rtAllCriticsNumRotten</th>\n",
       "      <th>rtAllCriticsScore</th>\n",
       "      <th>rtTopCriticsRating</th>\n",
       "      <th>rtTopCriticsNumFresh</th>\n",
       "      <th>...</th>\n",
       "      <th>country_Taiwan</th>\n",
       "      <th>country_Thailand</th>\n",
       "      <th>country_Tunisia</th>\n",
       "      <th>country_Turkey</th>\n",
       "      <th>country_UK</th>\n",
       "      <th>country_USA</th>\n",
       "      <th>country_Venezuela</th>\n",
       "      <th>country_Vietnam</th>\n",
       "      <th>country_West Germany</th>\n",
       "      <th>country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>9</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>8.5</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>5.9</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>7.7</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>86</td>\n",
       "      <td>7.2</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1954</td>\n",
       "      <td>9.2</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>8.6</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>7.5</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>87</td>\n",
       "      <td>6.9</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 406 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieID  rating  year rtAllCriticsRating rtAllCriticsNumFresh  \\\n",
       "0         1        1     4.0  1995                  9                   73   \n",
       "215       1        3     4.0  1993                5.9                   24   \n",
       "267       1        6     4.0  1995                7.7                   50   \n",
       "369       1       47     5.0  1954                9.2                   49   \n",
       "572       1       50     5.0  1995                7.5                   41   \n",
       "\n",
       "    rtAllCriticsNumRotten rtAllCriticsScore rtTopCriticsRating  \\\n",
       "0                       0               100                8.5   \n",
       "215                    12                66                  7   \n",
       "267                     8                86                7.2   \n",
       "369                     0               100                8.6   \n",
       "572                     6                87                6.9   \n",
       "\n",
       "    rtTopCriticsNumFresh  ... country_Taiwan country_Thailand country_Tunisia  \\\n",
       "0                     17  ...              0                0               0   \n",
       "215                    5  ...              0                0               0   \n",
       "267                   14  ...              0                0               0   \n",
       "369                   10  ...              0                0               0   \n",
       "572                   12  ...              0                0               0   \n",
       "\n",
       "    country_Turkey country_UK  country_USA  country_Venezuela  \\\n",
       "0                0          0            1                  0   \n",
       "215              0          0            1                  0   \n",
       "267              0          0            1                  0   \n",
       "369              0          0            0                  0   \n",
       "572              0          0            1                  0   \n",
       "\n",
       "     country_Vietnam  country_West Germany  country_Yugoslavia  \n",
       "0                  0                     0                   0  \n",
       "215                0                     0                   0  \n",
       "267                0                     0                   0  \n",
       "369                0                     0                   0  \n",
       "572                0                     0                   0  \n",
       "\n",
       "[5 rows x 406 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "there are >95000 actors, >4000 directors, >5000 tags. \n",
    "one-hot-encoding is not practical at this point, so we will not be using them as features.\n",
    "\n",
    "i am using pre-trained Google News Word2Vec model for tags aggregating\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# for each tag get average embeddings for each word,\n",
    "# multiply by the weight of that tag, \n",
    "# and take the average of all tags\n",
    "def get_avg_embedding_for_movie(row):\n",
    "    result = []\n",
    "    try:\n",
    "        for _, group in groupped.get_group(row['movieID']).iterrows():\n",
    "            text = np.array([w[word] for word in group['value'].split() if word in w.vocab])\n",
    "            if text.size>0:\n",
    "                result.append(text.mean(axis=0)*group['tagWeight'])\n",
    "    except KeyError:\n",
    "        return np.zeros(300)\n",
    "    return np.mean(result, axis=0)      \n",
    "\n",
    "\n",
    "datapath = '../../data/'\n",
    "hetrec = datapath + 'hetrec2011-movielens-2k-v2/'\n",
    "user_item_matrix = pd.read_csv(datapath + 'ml-latest-small/ratings.csv', usecols=[0, 1, 2]).rename(columns={'movieId':'movieID'})\n",
    "movies = pd.read_csv(datapath + 'ml-latest-small/movies.csv', usecols=[0, 1])\n",
    "\n",
    "# get rt metadata\n",
    "movies_meta = pd.read_csv(hetrec + 'movies.dat', sep='\\t', encoding='raw_unicode_escape').rename(columns={'id': 'movieID'}).drop(['spanishTitle', 'imdbID', 'title', 'imdbPictureURL', 'rtID', 'rtAllCriticsNumReviews', 'rtTopCriticsNumReviews', 'rtPictureURL'], axis=1)\n",
    "movies_meta = movies_meta[movies_meta['movieID'].isin(user_item_matrix['movieID'].unique())]\n",
    "\n",
    "# get the average tags embeddings\n",
    "movie_tags = pd.read_csv(hetrec + 'movie_tags.dat', sep='\\t')\n",
    "tags = pd.read_csv(hetrec + 'tags.dat', sep='\\t',  encoding='raw_unicode_escape').rename(columns={'id': 'tagID'})\n",
    "movie_tags = pd.merge(movie_tags, tags, on='tagID').sort_values(by=['movieID', 'tagID']).drop(['tagID'], axis=1)\n",
    "groupped = movie_tags.groupby('movieID')\n",
    "embedded_tags = pd.DataFrame.from_records(movies_meta.apply(get_avg_embedding_for_movie, axis=1), columns=[f'w2v_{i}' for i in range(1, 301)])\n",
    "movies_meta = pd.concat([movies_meta, embedded_tags], axis=1)\n",
    "\n",
    "user_item_matrix = pd.merge(user_item_matrix, movies_meta, on='movieID').sort_values(by=['userId','movieID'])\n",
    "\n",
    "# get a one-hot-encode-esque matrix of genres, then join on them\n",
    "movie_genres = pd.read_csv(hetrec + 'movie_genres.dat', sep='\\t').pivot_table(index=['movieID'], columns=['genre'], aggfunc=[len], fill_value=0)\n",
    "movie_genres.columns = movie_genres.columns.droplevel(0)\n",
    "movie_genres = movie_genres.reset_index()\n",
    "user_item_matrix = pd.merge(user_item_matrix, movie_genres, on='movieID')\n",
    "\n",
    "# get a one-hot-encode matrix of countries, then join on them\n",
    "movie_countries = pd.get_dummies(pd.read_csv(hetrec + 'movie_countries.dat', sep='\\t'))\n",
    "user_item_matrix = pd.merge(user_item_matrix, movie_countries, on='movieID').sort_values(by=['userId','movieID'])\n",
    "user_item_matrix.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w2v_1</th>\n",
       "      <th>w2v_2</th>\n",
       "      <th>w2v_3</th>\n",
       "      <th>w2v_4</th>\n",
       "      <th>w2v_5</th>\n",
       "      <th>w2v_6</th>\n",
       "      <th>w2v_7</th>\n",
       "      <th>w2v_8</th>\n",
       "      <th>w2v_9</th>\n",
       "      <th>w2v_10</th>\n",
       "      <th>...</th>\n",
       "      <th>w2v_291</th>\n",
       "      <th>w2v_292</th>\n",
       "      <th>w2v_293</th>\n",
       "      <th>w2v_294</th>\n",
       "      <th>w2v_295</th>\n",
       "      <th>w2v_296</th>\n",
       "      <th>w2v_297</th>\n",
       "      <th>w2v_298</th>\n",
       "      <th>w2v_299</th>\n",
       "      <th>w2v_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.146633</td>\n",
       "      <td>0.034206</td>\n",
       "      <td>0.023564</td>\n",
       "      <td>0.379975</td>\n",
       "      <td>-0.056800</td>\n",
       "      <td>0.037370</td>\n",
       "      <td>0.099820</td>\n",
       "      <td>-0.142083</td>\n",
       "      <td>0.062995</td>\n",
       "      <td>0.079154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.428080</td>\n",
       "      <td>0.298986</td>\n",
       "      <td>-0.227825</td>\n",
       "      <td>-0.051575</td>\n",
       "      <td>0.013310</td>\n",
       "      <td>-0.135927</td>\n",
       "      <td>0.023487</td>\n",
       "      <td>-0.110933</td>\n",
       "      <td>-0.033686</td>\n",
       "      <td>-0.043559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001071</td>\n",
       "      <td>0.205297</td>\n",
       "      <td>-0.092585</td>\n",
       "      <td>0.206977</td>\n",
       "      <td>0.120545</td>\n",
       "      <td>-0.089570</td>\n",
       "      <td>-0.014487</td>\n",
       "      <td>-0.038442</td>\n",
       "      <td>0.108484</td>\n",
       "      <td>0.103163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.205724</td>\n",
       "      <td>0.245217</td>\n",
       "      <td>-0.046846</td>\n",
       "      <td>0.029018</td>\n",
       "      <td>0.035965</td>\n",
       "      <td>-0.008839</td>\n",
       "      <td>-0.062912</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.062721</td>\n",
       "      <td>0.091470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093338</td>\n",
       "      <td>0.031871</td>\n",
       "      <td>0.060760</td>\n",
       "      <td>0.023626</td>\n",
       "      <td>0.037938</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>-0.098043</td>\n",
       "      <td>-0.084717</td>\n",
       "      <td>0.066945</td>\n",
       "      <td>0.095866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031238</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>-0.065247</td>\n",
       "      <td>-0.009633</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>-0.107625</td>\n",
       "      <td>-0.077189</td>\n",
       "      <td>-0.067759</td>\n",
       "      <td>-0.026549</td>\n",
       "      <td>0.069870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061117</td>\n",
       "      <td>-0.022502</td>\n",
       "      <td>-0.225342</td>\n",
       "      <td>0.215394</td>\n",
       "      <td>-0.019953</td>\n",
       "      <td>0.080668</td>\n",
       "      <td>0.054207</td>\n",
       "      <td>-0.241842</td>\n",
       "      <td>0.179227</td>\n",
       "      <td>0.064585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156729</td>\n",
       "      <td>0.016235</td>\n",
       "      <td>-0.275055</td>\n",
       "      <td>-0.072570</td>\n",
       "      <td>0.162170</td>\n",
       "      <td>0.133728</td>\n",
       "      <td>-0.202593</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.108437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      w2v_1     w2v_2     w2v_3     w2v_4     w2v_5     w2v_6     w2v_7  \\\n",
       "0  0.146633  0.034206  0.023564  0.379975 -0.056800  0.037370  0.099820   \n",
       "1 -0.001071  0.205297 -0.092585  0.206977  0.120545 -0.089570 -0.014487   \n",
       "2  0.093338  0.031871  0.060760  0.023626  0.037938  0.001200 -0.098043   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.061117 -0.022502 -0.225342  0.215394 -0.019953  0.080668  0.054207   \n",
       "\n",
       "      w2v_8     w2v_9    w2v_10  ...   w2v_291   w2v_292   w2v_293   w2v_294  \\\n",
       "0 -0.142083  0.062995  0.079154  ... -0.428080  0.298986 -0.227825 -0.051575   \n",
       "1 -0.038442  0.108484  0.103163  ... -0.205724  0.245217 -0.046846  0.029018   \n",
       "2 -0.084717  0.066945  0.095866  ... -0.031238  0.073242 -0.065247 -0.009633   \n",
       "3  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4 -0.241842  0.179227  0.064585  ... -0.156729  0.016235 -0.275055 -0.072570   \n",
       "\n",
       "    w2v_295   w2v_296   w2v_297   w2v_298   w2v_299   w2v_300  \n",
       "0  0.013310 -0.135927  0.023487 -0.110933 -0.033686 -0.043559  \n",
       "1  0.035965 -0.008839 -0.062912  0.002716  0.062721  0.091470  \n",
       "2  0.006348 -0.107625 -0.077189 -0.067759 -0.026549  0.069870  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.162170  0.133728 -0.202593 -0.000427  0.149015  0.108437  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "w = models.KeyedVectors.load_word2vec_format('/media/thejdxfh/Windows/Users/volok/Desktop/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_item_matrix.shape\n",
    "give_test = lambda obj: obj.loc[np.random.choice(obj.index, len(obj.index)//10),:]\n",
    "test_data = user_item_matrix.groupby('userId', as_index=False).apply(give_test).reset_index(level=0, drop=True)\n",
    "train_data = user_item_matrix[~user_item_matrix.index.isin(test_data.index)]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_avg_embedding_for_movie(row):\n",
    "    global groupped\n",
    "\n",
    "    result = []\n",
    "    try:\n",
    "        print(row['movieID'])\n",
    "        for _, group in groupped.get_group(row['movieID']).iterrows():\n",
    "            text = np.array([w[word] for word in group['value'].split() if word in w.vocab])\n",
    "            if text.size > 0:\n",
    "                result.append(text.mean(axis=0) * group['tagWeight'])\n",
    "    except KeyError:\n",
    "        return np.zeros(300)\n",
    "    if len(result)<1:\n",
    "        return np.zeros(300)\n",
    "    print(np.mean(result, axis=0))\n",
    "    return np.mean(result, axis=0)\n",
    "\n",
    "\n",
    "# def process_data(device, batch_size):\n",
    "    \n",
    "\n",
    "datapath = '../data/'\n",
    "hetrec = datapath + 'hetrec2011-movielens-2k-v2/'\n",
    "user_item_matrix = pd.read_csv(datapath + 'ml-latest-small/ratings.csv', usecols=[0, 1, 2]).rename(columns={'movieId': 'movieID'})\n",
    "movies = pd.read_csv(datapath + 'ml-latest-small/movies.csv', usecols=[0, 1])\n",
    "\n",
    "# get rt metadata\n",
    "movies_meta = pd.read_csv(hetrec + 'movies.dat', sep='\\t', encoding='raw_unicode_escape').rename(columns={'id': 'movieID'}).drop(['spanishTitle', 'imdbID', 'title', 'imdbPictureURL', 'rtID', 'rtAllCriticsNumReviews', 'rtTopCriticsNumReviews', 'rtPictureURL'], axis=1)\n",
    "movies_meta = movies_meta[movies_meta['movieID'].isin(user_item_matrix['movieID'].unique())]\n",
    "\n",
    "# get the average tags embeddings\n",
    "movie_tags = pd.read_csv(hetrec + 'movie_tags.dat', sep='\\t')\n",
    "tags = pd.read_csv(hetrec + 'tags.dat', sep='\\t', encoding='raw_unicode_escape').rename(columns={'id': 'tagID'})\n",
    "movie_tags = pd.merge(movie_tags, tags, on='tagID').sort_values(by=['movieID', 'tagID']).drop(['tagID'], axis=1)\n",
    "groupped = movie_tags.groupby('movieID')\n",
    "\n",
    "embedded_tags = pd.DataFrame.from_records(movies_meta.tail().apply(get_avg_embedding_for_movie, axis=1), columns=[f'w2v_{i}' for i in range(1, 301)])\n",
    "# embedded_tags\n",
    "#     movies_meta = pd.concat([movies_meta, embedded_tags], axis=1)\n",
    "\n",
    "#     user_item_matrix = pd.merge(user_item_matrix, movies_meta, on='movieID').sort_values(by=['userId', 'movieID'])\n",
    "\n",
    "#     # get a one-hot-encode-esque matrix of genres, then join on them\n",
    "#     movie_genres = pd.read_csv(hetrec + 'movie_genres.dat', sep='\\t').pivot_table(index=['movieID'], columns=['genre'], aggfunc=[len], fill_value=0)\n",
    "#     movie_genres.columns = movie_genres.columns.droplevel(0)\n",
    "#     movie_genres = movie_genres.reset_index()\n",
    "#     user_item_matrix = pd.merge(user_item_matrix, movie_genres, on='movieID')\n",
    "\n",
    "#     # get a one-hot-encode matrix of countries, then join on them\n",
    "#     movie_countries = pd.get_dummies(pd.read_csv(hetrec + 'movie_countries.dat', sep='\\t'))\n",
    "#     user_item_matrix = pd.merge(user_item_matrix, movie_countries, on='movieID').sort_values(by=['userId', 'movieID'])\n",
    "\n",
    "#     user_item_matrix.to_csv('user_item_matrix.tsv', sep='\\t', index=False)\n",
    "\n",
    "#     give_test = lambda obj: obj.loc[np.random.choice(obj.index, len(obj.index) // 10), :]\n",
    "#     test_data = user_item_matrix.groupby('userId', as_index=False).apply(give_test).reset_index(level=0, drop=True)\n",
    "#     train_data = user_item_matrix[~user_item_matrix.index.isin(test_data.index)]\n",
    "\n",
    "#     # user item stats\n",
    "#     all_data = user_item_matrix\n",
    "#     num_user = len(all_data['userId'].unique()) + 1\n",
    "#     num_item = len(all_data['movieID'].unique()) + 1\n",
    "\n",
    "#     # convert input to torch tensors\n",
    "#     train_tensors = [torch.tensor(columnData.values, device=device) for _, columnData in train_data.iteritems()]\n",
    "#     test_tensors = [torch.tensor(columnData.values, device=device) for _, columnData in test_data.iteritems()]\n",
    "\n",
    "#     # convert tensors to dataloader\n",
    "#     train_dataset = data.TensorDataset(*train_tensors)\n",
    "#     train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#     test_dataset = data.TensorDataset(*test_tensors)\n",
    "#     test_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "#     print('train_samples:{} \\t test_samples:{} \\t num_user:{} \\t num_item:{}'.format(train_data.shape[0], test_data.shape[0], num_user, num_item))\n",
    "#     return train_loader, test_loader, num_user, num_item"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
